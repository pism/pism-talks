Story-line

Before I start, I'd like to blame any inconsistencies in my talk to the fire alarm in the GI this morning.

Title Slide

Today I'd like to share my thoughts about the credibility of sea-level projections made with numerical ice sheet models. The title is already a give-away; I don't think the community's latest projections are very credible.

Slide "Modern sea-level change"

Over the past 25 years, global mean sea level has risen at a rate of about 3 mm per year, as measured from satellite altimetry. Between 1993 and 2018, Greenland and Antarctica contributed about 25% to sea-level rise.

However, focusing on the more recent history from 2006 until 2018, the contribution of the ice sheets increased to 35%. Clearly, if we want to predict future sea-level, we need to understand the role of the ice sheets within the climate system, and how much they will contribute to sea-level rise.

Slide "IPCC AR4, 2007"

To understand where we are today we need to go back to 2007, when the Intergovernmental Panel on Climate Change released its forth assessment report. The IPCC did not include any ice sheet model-based projections because, at that time, the models were not able to track observed changes in Greenland and Antarctica.

Slide "Observed vs simulated flow speeds (2007 model)"

Why was that? If we took all the data available in 2007 and feed it into model from 2007, the result would look like the figure here. On the left side you see the observed surface speeds in meters per year, where blue and red colors indicate fast flow. The fast flow is concentrated near the coast. The model, on the right side, does not show much fast flow, blue and red colors are mostly missing.

The poor performance of the models and the exclusion from IPCC led to a frenzy in model development. Each group tried to up their game, mainly focusing on implementing better approximations to the conservation of momentum equations. That was about the time when I joined the ice sheet modeling group of Ed Bueler here at UAF in 2009.

Slide "IPCC AR5, 2013"

Fast forward a couple of years to 2013. Now, with better ice sheet models at hand, a group of modelers formed the Sea-level Response to Ice Sheet Evolution or SeaRISE community effort. For the first time, modelers performed a standardized set of experiments, aimed at estimating mass loss from the ice sheets.

If we go into IPCC's fifth assessment report, we will find the SeaRISE effort only mentioned in passing, along with a single study. While that study appeared in Nature, the model used was basic and only two dimensional along a flow-line. Again, models were deemed untrustworthy.

Slide "Observed vs simulated flow speeds (2013 model)"

Let's do the same exercise again. This time we use data and a model representative of 2013. As you can see, the result remains more or less the same. The models are still not able to to capture the fast flow in Greenland's coastal areas. So what's going on?

Slide "Post 2014 models"

2014 was a watershed moment for modeling the Greenland Ice Sheet. While the models kept getting better, it wasn't model improvements that did the trick. It was a 100 Million Dollar investment by NASA. Their Operation Ice Bridge spent 10 years mapping ice thicknesses all across Greenland, particularly in coastal areas. As glaciers generally flow downhill, ice thickness exerts a first order control on ice flow. Without accurate ice thicknesses you can't accurately reproduce ice flow. In that sense, when you have garbage coming in, you get garbage coming out.

With a new ice thickness data set released in 2014, models finally have become decent at reproducing present-day ice flow patterns.

Slide "IPCC AR6, 2021"

In same year of 2014, the community effort "Ice Sheet Model Intercomparison Project for CMIP6" was started, with the goal of projection mass loss from Greenland and Antarctica for IPCC AR6. About 15 modeling groups world-wide participated in ISMIP6 to produce the first multi-model ensemble projections. With little to no funding available.

Slide "Modern and projected mass loss from Greenland"

This is Figure 9.17 in AR6. It shows the ISMIP6 projections for two emission pathways, the historical simulations, and observations. Projected 21st century mass loss ranges from about 0 to 25cm, with medians of 6 and 13 cm. Finally we made it into IPCC.

Slide "Case closed"

So are we done now, is it "all sunshine and rainbows"?

Wait a minute. This is not how I remember the draft of Figure 9.17 looked like when it was released in March 2020. And it was not just me. Martin Truffer noticed it, too. And so did our former students, Tim Bartholomaus and Doug Brinkerhoff.

Slide "Modern and project mass loss from Greenland II"

The draft figure showed a kink at the transition from the historical simulations to the projections. The historical simulations are needed to generate an initial state for 2015, the start of the projections. How the historical simulations were done was left up to the individual modelers.

Anyway, let's zoom in around 2015. IMBIE is a reconstruction based on observations, the historical simulations are not shown in the plot. But the transition looks rather smooth, lacking a kink.

Here is a screen shot of the original draft figure, clearly showing a change in slope.

Slide "A closer look"

We were unable to follow what IPCC did with the ISMIP6 projections and decided a closer look was needed. We downloaded the ISMIP6 simulations from the official repository and made our own plots.

The figure shows the IMBIE observations in blue, and the ISMIP6 simulations in gray. The ISMIP6 mean in shown in black. It's pretty obvious that the ISMIP6 mean under-estimates the historical trend. Instead ISMIP6 mean  closely tracks the 95th percentile.

The question now arises: can we trust projections made with models that under-estimate the historical trend. Wouldn't you expect the models to under-estimate future mass loss too? We summarized our concerns in an opinion paper that is currently in press.

The whole situation was a deja-vu. But what did it remind me of?

Slide "Modern and projected Arctic sea ice extend"

Oh yes, right. Back in 2007, Arctic sea ice loss was all over the news. The plot shows Arctic sea ice extend, both modeled, and observed (in blue). No model at that time was able to reproduce the observed rapid decline.

How do we go from here?

In the second part of my talk, let me paint a way forward.

Part II

Slide "2 key requirements"

In our opinion, accurate predictions of the cryosphere's contribution to sea level require that models:

button

1. Fully characterize uncertainties in model structure, parameters, initial conditions, and boundary conditions.

button

2. Yield simulations that fit observations within observational uncertainty.

In the remainder of the talk, I will focus on the second point: that historical simulations fit observations.


Slide "The first large ensemble projections for Greenland"

In 2019 we published a paper that assessed the future of the Greenland Ice Sheet in a probabilistic way. We ran 500 simulations with slightly varying parameters. Our work was the first to rigorously quantify parametric uncertainty.

Slide "AS19 Ensemble Projections"

The results are shown in the upper figure. The figure shows the median, 5-95th and 16-84th percentiles for three RCP scenarios. As you can see, the variance is pretty large. This is a feature of our approach, not a bug. We varied several parameters within their published uncertainty range. And not on what we thought they ought to be. In the figure below, you see examples of the prior distributions we chose. Most priors were uniform distributions, but it looks jagged because the 500 member ensemble does not completely fill the parameter space.

Slide "What's wrong with AS19"

While our work was rather ground breaking, it also had its deficiencies. Just like the ISMIP6 efforts, we did not condition our projections on observations.

Slide "A Bayesian calibration in two steps"

Doug developed a two step probabilistic calibration method to condition projections on historical observations. But which observations should we use? A natural choice is the quantity of interest. In our case, we want to predict mass loss so let's use mass change. Second we use surface speeds because our 2019 work showed that uncertainties in ice flow parameters contribute a lot to uncertainties in mass loss.

Slide "1. Ice Flow calibration: strategy"

Let's start with calibrating ice flow parameters. How do we do this probabilistic ally? Our strategy is to use Markov Chain Monte Carlo sampling to find the joint distribution of parameters given observations. Let's think of the ice sheet model as a map F from a parameter vector x to surface speeds Y. While our ice sheet model PISM is relatively computationally efficient, it is too expensive to run it 100s of thousands of times, needed for MCMC. To skirt the issue, we instead use a computationally cheap surrogate model G that approximates the ice flow model F.

Slide "1. Ice Flow calibration: surrogate model"

We adapted the 4 layer Neural Network surrogate model that Doug had developed earlier. The model is implemented in PyTorch and PyTorch-Lightning, and we can train the model on GPUs.


Slide "1. Ice Flow calibration: dimensionality reduction"

There is a caveat. Y is not a scalar but the number of grid points (observations), which is on the order of 10 to the power of six. So we have a map from 8 parameters to 1,000,000 points. That's hard.

The genius part of Doug's approach is to use Principal Component Analysis to reduce the dimension of Y. Fortunately we only need the first 100-ish eigen-coefficients or as we call them, eigen-glaciers, to create a good surrogate model. Now we have reduced the problem from 1,000,000 to 100 unknowns. Not bad.

The figure shows the first three eigen-glaciers and they explained variance.

Slide "1. Ice Flow calibration: training data"

Now we need data to train the surrogate model on. First we select eight parameters that describe ice flow. For each parameter we prescribe a prior distribution. Next we draw 1000 samples using Sobol Sequences. Then we run the ice sheet model 1000 times, once for each parameter combination.

Slide "1. Ice Flow calibration: surrogate model"

Using the trained surrogate model, we create a much larger ensemble, this time with 1,000,000 member. This is much cheaper than running PISM 1000 times. Then we sample from this 1,000,000 member strong ensemble using a Markov Chain Monte Carlo Method, given observations. What you get are the posterior distributions of the eight parameters. These distributions best reproduce the surface speed observations.

Slide "Use posterior as new prior"

Now we create 500 samples from the posterior to redo the 2019 modeling effort. The difference to the 2019 ensemble is that we now only sample from the parameter space that can reproduce the observed surface speeds. Running PISM 500 times for a 100 model years takes a moment, so let's wait. The results are new projections, condition on surface speeds. What we find is that now the variance is greatly reduced, as well as the median.

Slide "2. Mass Loss: Bayesian calibration"

The second step is the actual Bayesian calibration. Here we weight ensemble members based on their likelihood relative to observations of mass change. We resample simulations proportionally to these likelihoods to create a new ensemble that is consistent with respect to both observations of surface speed and mass change to within observational uncertainty. Now we have fully calibrated projections that are conditioned. The variance is reduced even further. We believe this is a step towards credible projections of future mass loss from ice sheets.

Slide "Final thoughts"

For the first part, "Fully characterize uncertainties in model structure, parameters, initial conditions, and boundary conditions", we addressed parametric uncertainty.

And we presented a first step towards the second point, "Yield simulations that fit observations within observational uncertainty."

Artificial Intelligence and Machine Learning have become buzzwords. What I like here is that we use the surrogate model only for calibration of the high-fidelity model, while we use the high-fidelity model for the actual projections.

